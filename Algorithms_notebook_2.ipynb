{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision as tv\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy example\n",
    "Take an image, and add some noise to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference operator\n",
    "The difference operator is like a convolution by a particular kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_operator():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal operators\n",
    "We can calculate the proximal operators for each of the terms of the sum separately, then use these separate computations in an algorithm such as forward-backward or ADMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximal_L2():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating the finite difference operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lagrangian formulation\n",
    "\n",
    "We could treat the problem as minimizing\n",
    "\n",
    "$$\\frac{1}{2}\\|Ax-b\\|^2_2 + \\|y\\|_1$$\n",
    "under the constraints $y = Dx$ and $x\\in C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deblurring the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Several algorithms for optimizing the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image_bw(path, downsample=1):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    ])\n",
    "    img = Image.open(path)\n",
    "    original_width, original_height = img.size\n",
    "    img = img.convert('L')\n",
    "    img = img.resize((original_width // downsample, original_height // downsample))\n",
    "    return transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_dog_tensor = open_image_bw('dog.jpg', downsample=10)\n",
    "disc_tensor = open_image_bw('rond.jpg', downsample=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiniteDifference(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        filter = torch.tensor([\n",
    "            [-1, 1],\n",
    "            [0, 0]\n",
    "        ], dtype=torch.float32).reshape(1, 1, 2, 2)\n",
    "        filter = filter / torch.norm(filter, p=2)\n",
    "        self.filter = nn.Parameter(filter, requires_grad=False)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        return torch.nn.functional.conv2d(image, self.filter, padding = 1)\n",
    "\n",
    "class GaussianBlur(nn.Module):\n",
    "    def __init__(self, kernel_size, sigma):\n",
    "        super().__init__()\n",
    "        self.gaussian_blur = tv.transforms.GaussianBlur(kernel_size, sigma)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        return self.gaussian_blur(image)\n",
    "    \n",
    "class ReconstructionLoss(nn.Module):\n",
    "    def __init__(self, image, penalty_weight, gaussian_std, kernel_size):\n",
    "        super().__init__()\n",
    "        self.image = nn.Parameter(image, requires_grad=False)\n",
    "        self.gaussian_blur = GaussianBlur(kernel_size=kernel_size, sigma=gaussian_std)\n",
    "        self.finite_difference = FiniteDifference()\n",
    "        reconstruction = image.clone().detach()\n",
    "        self.reconstruction = nn.Parameter(reconstruction, requires_grad=True)\n",
    "        self.penalty_weight = nn.Parameter(torch.tensor(penalty_weight), requires_grad=False)\n",
    "    def forward(self):\n",
    "        blurred_reconstruction = self.gaussian_blur(self.reconstruction)\n",
    "        l2_loss = 1/2 * torch.norm(blurred_reconstruction - self.image, p=2)**2\n",
    "        finite_difference_reconstruction = self.finite_difference(self.reconstruction)\n",
    "        l1_loss = torch.norm(finite_difference_reconstruction, p=2)\n",
    "        return l2_loss + self.penalty_weight*l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(image, std_noise, gaussian_std=10, kernel_size=51, print_image=True,image_size=(1500,900)):\n",
    "    # Gaussian blur + noise\n",
    "    # Show original\n",
    "    printed_image = image.clone().detach()\n",
    "    if print_image:\n",
    "        print(f\"original shape {printed_image.shape}\")\n",
    "    printed_image = transforms.ToPILImage()(printed_image).resize(image_size)\n",
    "    if print_image:\n",
    "        display(printed_image)\n",
    "    noise = torch.randn(image.shape) * std_noise\n",
    "    blurred_image = tv.transforms.functional.gaussian_blur(image, kernel_size=kernel_size, sigma=gaussian_std)\n",
    "    noisy_image = blurred_image + noise\n",
    "    noisy_image = torch.clamp(noisy_image, 0, 1)\n",
    "    printed_image = noisy_image.clone().detach()\n",
    "    if print_image:\n",
    "        print(f\"new shape {printed_image.shape}\")\n",
    "    printed_image = transforms.ToPILImage()(printed_image).resize(image_size)\n",
    "    if print_image:\n",
    "        display(printed_image)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "gaussian_std = 0.001\n",
    "std_noise = 0.03\n",
    "noisy_image = add_noise(gray_dog_tensor, std_noise=std_noise, gaussian_std=gaussian_std, kernel_size=kernel_size, print_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "gaussian_std = 0.001\n",
    "std_noise = 0.03\n",
    "noisy_image = add_noise(gray_dog_tensor, std_noise=std_noise, gaussian_std=gaussian_std, kernel_size=kernel_size, print_image=False)\n",
    "print(f\"{kernel_size=}, {gaussian_std=}\")\n",
    "reconstruction_module = ReconstructionLoss(noisy_image, penalty_weight=0.5, gaussian_std=gaussian_std, kernel_size=kernel_size)\n",
    "# Now optimize the reconstruction module\n",
    "optimizer = torch.optim.AdamW(reconstruction_module.parameters(), lr=0.01)\n",
    "#reconstruction_module.to('cuda')\n",
    "pbar = tqdm(range(1000))\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    loss = reconstruction_module()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        pbar.set_description(f\"Loss: {loss.item():.9f}\")\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        # Clear the previous output\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Epoch {i}, Loss: {loss.item()}\")\n",
    "        \n",
    "        # Clone the tensor, detach it from the computation graph, and move it to CPU\n",
    "        result = reconstruction_module.reconstruction.clone().detach().cpu()\n",
    "        # Convert to PIL image\n",
    "        pil_image = transforms.ToPILImage()(result).resize((1500,900))\n",
    "        # Display the image in the notebook\n",
    "        display(pil_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condat-Vu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère le problème d'optimisation:\n",
    "\\begin{equation}\n",
    "\\min_{x \\in \\mathbb{R^{n \\times n} }} \\frac{1}{2} \\|x-z \\|_{2}^{2} + \\lambda \\| Dx \\|_{1} + i_c(x)\n",
    "\\end{equation}\n",
    "où $C = \\{ u \\in \\mathbb{R}^{n \\times n} | \\|u-z \\|_{2}^{2} \\leq \\sigma ^2 \\} $, $\\lambda >0$ et $D$ l'opérateur de différences finies.\n",
    "\n",
    "\n",
    "Nous allons appliquer l'algorithme de Condat-Vu, avec $f= i_c$,$h = \\frac{1}{2} \\| \\cdot -z \\| _{2}^{2}$, $g=\\| \\cdot \\|_{1}$ et $L = D$.\n",
    "\n",
    "\n",
    "On calcule:\n",
    "\n",
    "\\begin{equation}\n",
    "prox_{\\tau f} (x) = P_{C}(x)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "prox_{\\gamma g^{*}} (x) = (\\varphi (x_i) )_{1 \\leq i \\leq n^2 }\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla{h}(x) = x-z\n",
    "\\end{equation}\n",
    "où:\n",
    "\\begin{equation}\n",
    "\\begin{array}{l|rcl}\n",
    "\\varphi : & \\mathbb{R} & \\longrightarrow & \\mathbb{R} \\\\\n",
    "    & x & \\longmapsto & \\begin{cases}-1 \\text{ , si $x<-1$,} \\\\ x \\text{ , si $|x| \\leq 1$,} \\\\ 1 \\text{ , si $x>1$,} \\end{cases}\n",
    "    \\end{array}\n",
    "    \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calcul des prox de f et g\n",
    "\n",
    "def prox_f(x,z,sigma):\n",
    "    if torch.linalg.norm(x-z)>sigma:\n",
    "        return sigma*(x-z)/torch.linalg.norm(x-z) + z \n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def varphi(x):\n",
    "    if x<-1:\n",
    "        return -1\n",
    "    if x>1:\n",
    "        return 1\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def prox_g(x):\n",
    "    y=torch.zeros(size=x.size())\n",
    "    for i in range(x.size()[2]):\n",
    "        for j in range(x.size()[3]):\n",
    "            y[0,:,i,j]=varphi(x[0,:,i,j])\n",
    "            y[1,:,i,j]=varphi(x[1,:,i,j])\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#D et D^T\n",
    "\n",
    "def GradientHor(x):\n",
    "    y=x-torch.roll(x,1,dims=2)\n",
    "    y[0,:,0]=0\n",
    "    return y\n",
    "\n",
    "def GradientVer(x):\n",
    "    y=x-torch.roll(x,1,dims=1)\n",
    "    y[0,0,:]=0\n",
    "    return y\n",
    "\n",
    "def DivHor(x):\n",
    "    N=(x[0,0]).numel()\n",
    "    y=x-torch.roll(x,-1,dims=2)\n",
    "    y[0,:,0]=-x[0,:,1]\n",
    "    y[0,:,N-1]=x[0,:,N-1]\n",
    "    return y\n",
    "\n",
    "def DivVer(x):\n",
    "    N=len(x[0])\n",
    "    y=x-torch.roll(x,-1,dims=1)\n",
    "    y[0,0,:]=-x[0,1,:]\n",
    "    y[0,N-1,:]=x[0,N-1,:]\n",
    "    return y\n",
    "\n",
    "def Psi(x):\n",
    "    y=[]\n",
    "    y.append(GradientHor(x).numpy())\n",
    "    y.append(GradientVer(x).numpy())\n",
    "    y=np.asarray(y)\n",
    "    return torch.asarray(y)\n",
    "\n",
    "def Psit(y):\n",
    "    x=DivHor(y[0])+DivVer(y[1])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Condat-Vu\n",
    "\n",
    "def condat_vu(x_0,v_0,z, n_max, tau, gamma, sigma):\n",
    "    p = []\n",
    "    q = []\n",
    "    x = [x_0]\n",
    "    v = [v_0]\n",
    "    lambda_ = 1\n",
    "\n",
    "    for n in range(n_max):\n",
    "        p.append( prox_f( x[-1] - tau*(x[-1] -z + Psit(v[-1])), z, sigma))\n",
    "        q.append( prox_g( v[-1] + gamma*( Psi(2*p[-1] - x[-1]) ) ) )\n",
    "        x_temp,v_temp=x[-1],v[-1]\n",
    "        x.append(x_temp + lambda_*(p[-1] - x_temp))\n",
    "        v.append(v_temp + lambda_*(q[-1] - v_temp))\n",
    "        print(n)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kernel_size = 1\n",
    "gaussian_std = 0.001\n",
    "std_noise = 0.2\n",
    "noisy_image_2 = add_noise(gray_dog_tensor, std_noise=std_noise, gaussian_std=gaussian_std, kernel_size=kernel_size, print_image=True)\n",
    "noisy_image_3 = add_noise(disc_tensor, std_noise=std_noise, gaussian_std=gaussian_std, kernel_size=kernel_size, print_image=True,image_size=(800,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0=noisy_image_2.clone().detach()\n",
    "v_0=Psi(x_0)\n",
    "z=noisy_image_2.clone().detach()\n",
    "iteration_2=condat_vu(x_0,v_0,z,n_max=5,tau=0.1,gamma=0.3,sigma=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_0=noisy_image_3.clone().detach()\n",
    "v_0=Psi(x_0)\n",
    "z=noisy_image_3.clone().detach()\n",
    "iteration_3=condat_vu(x_0,v_0,z,n_max=25,tau=0.1,gamma=0.3,sigma=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_3= torch.clamp(iteration_3[-1],0,1)\n",
    "image_3.size()\n",
    "pimage_3 = transforms.ToPILImage()(image_3).resize((800,800))\n",
    "# Display the image in the notebook\n",
    "display(pimage_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_2= torch.clamp(iteration_2[-1],0,1)\n",
    "image_2.size()\n",
    "pimage_2 = transforms.ToPILImage()(image_2).resize((1500,900))\n",
    "# Display the image in the notebook\n",
    "display(pimage_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Checking the convergence speed for each of the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_logger():\n",
    "    # this function logs the value of the loss function, and the time taken by the iteration\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of convergence. Do a loglog plot of the losses vs. iteration number, and vs. time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testing the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
